<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Structure and Interpretation of Deep Networks</title>

<!-- Bootstrap CSS Imports -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">

<!-- Google Font Imports -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap"
rel="stylesheet">

<!-- Custom CSS Imports -->
<link rel="stylesheet" href="/css/style.css">

<!-- Mathjax -->
<script sid="MathJax-script" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js" integrity="sha512-6FaAxxHuKuzaGHWnV00ftWqP3luSBRSopnNAA2RvQH1fOfnF/A1wOfiUWF7cLIOFcfb1dEhXwo5VG3DAisocRw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<!-- jQuery -->
<script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>

<!-- Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js" integrity="sha256-3gQJhtmj7YnV1fmtbVcnAV6eI4ws0Tr48bVZCThtCGQ=" crossorigin="anonymous"></script>

<!-- Auto Table of Contents -->
<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css"
/>
<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script>

</head>

<body data-bs-spy="scroll" data-bs-target="#toc">
<nav class="navbar navbar-dark bg-dark">
<div class="container-fluid">
<ul class="navbar-nav mr-auto">
 <li class="nav-item active">
  <a class="nav-link" href="/neurons/index.html">Neuron Interpretation</a>
 </li>
</ul>
<ul class="navbar-nav ml-auto">
 <li class="nav-item">
  <a class="navbar-brand" href="/">Structure and Intrepretation of Deep Networks</a>
 </li>
</ul>
</div>
</nav>

<div class="container">
<div class="row">
<div class="col-2 position-fixed pt-5">
<nav id="toc" data-toggle="toc"></nav>
</div>
<div class="col-2"></div>
<main class="col-8">
<h1 class="mt-5">Neuron Interpretation</h1>


<!--
<p>
An ideal explanation for a network's decision would deal with
higher-level variables than raw inputs such as pixels. Rather than explaining
a "dog image" by pointing out any individual pixel or even a set of pixels,
an ideal explanation might point "there are four legs here", "there is a dark
nose here"; "there is a floppy ear there"; "there is some curly fur there."
-->

<p>
What are the high-level concepts that a deep network reasons about?
Since a network is made of many layers, the inputs to each layer are
the outputs from the previous layers, so it stands to reason that the
individual neurons on each layer form the "meaningful" input variables
for the subsequent layers of the network.

<p>
Thus the second early line of work in understanding deep networks was
<em>neuron interpretation</em>, in which researchers examined individual
neurons to try to discern their meaning.

<h3>Maximal-Response Visualizations of Neurons</h3>

<p>
One of the most common ways to understand the role of a neuron
is to ask the question: "what input causes this neuron to fire most strongly?"

<p>
In <a href="https://papers.baulab.info/papers/also/Erhan-2009.pdf">2009,
Dumitru Erhan</a> wrote <em>Visualizing Higher-Layer Features of a Deep Network</em>,
where he proposed analyzing the components of a neural network by identifying the
inputs that caused them to maximize their output.  That is, writing
\( h_{ij}( \theta, x) \) as the value of the neuron \( h_{ij} \) within a network
with parameters \( \theta \) in response to the input \( x \), he proposed understanding
the neuron by identifying and visualizing the maximizing input

\[ x^* = \arg\max_{x \text{ s.t. } ||x|| = \rho} h_{ij}(\theta, x) \]

<p>
Erhan proposed maximizing input \( x^* \) can be found through
gradient descent.  By starting with a random or arbitrary \( x \),
optimizing towards \( x^* \) could reveal an image that the
neuron is looking for, a picture of the "concept" for \( h_{ij} \).

<p>
Several modifications to the optimization algorithm were proposed by a series
of papers; an excellent feature visualization method that incorporates
many of the techniques was developed by <a href="https://distill.pub/2017/feature-visualization/"
>Chris Olah (2017)</a>, and was used to visualize all the units of several
networks at the <a href="https://microscope.openai.com/models">OpenAI Microscope</a>
website.


</main>
</div>
</div>
</body>
</html>

