{header('Neuron Interpretation')}

<p>
An ideal explanation for a network's decision would deal with
higher-level variables than raw inputs such as pixels. Rather than explaining
a "dog image" by pointing out any individual pixel or even a set of pixels,
an ideal explanation might point "there are four legs here", "there is a dark
nose here"; "there is a floppy ear there"; "there is some curly fur there."

<p>
But what are the high-level concepts that a deep network reasons about?
Since a network is made of many layers, the inputs to each layer are
the outputs from the previous layers, so it stands to reason that the
individual neurons on each layer form the "meaningful" input variables
for the subsequent layers of the network.

<p>
Thus the second early line of work in understanding deep networks was
<em>neuron interpretation</em>, in which researchers examined individual
neurons to try to discern their meaning.

<h3>Maximal-Response Visualizations of Neurons</h3>

<p>
One of the most common ways to understand the role of a neuron
is to ask the question: "what input causes this neuron to fire most strongly?"

<p>
In <a href="https://papers.baulab.info/papers/also/Erhan-2009.pdf">2009,
Dumitru Erhan</a> wrote <em>Visualizing Higher-Layer Features of a Deep Network</em>,
where he proposed analyzing the components of a neural network by identifying the
inputs that caused them to maximize their output.  That is, writing
\( h_{ij}( \theta, x) \) as the value of the neuron \( h_{ij} \) within a network
with parameters \( \theta \) in response to the input \( x \), he proposed understanding
the neuron by identifying and visualizing the maximizing input

\[ x^* = \arg\max_{x \text{ s.t. } ||x|| = \rho} h_{ij}(\theta, x) \]

<p>
Erhan proposed maximizing input \( x^* \) can be found through
gradient descent.  By starting with a random or arbitrary \( x \),
optimizing towards \( x^* \) could reveal an image that the
neuron is looking for, a picture of the "concept" for \( h_{ij} \).

<p>
Several modifications to the optimization algorithm were proposed by a series
of papers; an excellent feature visualization method that incorporates
many of the techniques was developed by <a href="https://distill.pub/2017/feature-visualization/"
>Chris Olah (2017)</a>, and was used to visualize all the units of several
networks at the <a href="https://microscope.openai.com/models">OpenAI Microscope</a>
website.

{footer()}
